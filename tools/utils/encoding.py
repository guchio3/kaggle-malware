import gc
from functools import partial
from multiprocessing import Pool

import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from tqdm import tqdm


def label_encoding(df, le_dict={}, fit_columns=[], inplace=False):
    '''
    label encoding object type object

    '''
    if not inplace:
        df = df.copy()

    # fit
    print('fitting ...')
    for col in tqdm(fit_columns):
        if df[col].dtype in ['int8', 'int16', 'float16',
                             'int32', 'float32', 'int64', 'float64']:
            filled = df[col].fillna(-111111111)
        elif df[col].dtype == 'object' or df[col].dtype == 'category':
            df[col] = df[col].astype(str)
            filled = df[col].fillna('NAN!!!!!!!!')
        le = LabelEncoder()
        le.fit(filled)
        le_dict[col] = le

    # transform
    print('transforming ...')
    transformed_cols = []
    for col in tqdm(df.columns):
        if col not in le_dict:
            continue
        transformed_cols.append(col)
        le = le_dict[col]

        # $B7gB;$,$"$k>l9g(B
        is_deficit = df[col].isnull().sum() > 0
        if is_deficit:
            if df[col].dtype in ['int8', 'int16', 'float16',
                                 'int32', 'float32', 'int64', 'float64']:
                df[col].fillna(-111111111, inplace=True)
                fill_symbol = le.transform([-111111111])[0]
            elif df[col].dtype == 'object' or df[col].dtype == 'category':
                df[col] = df[col].astype(str)
                df[col].fillna('NAN!!!!!!!!', inplace=True)
                fill_symbol = le.transform(['NAN!!!!!!!!'])[0]

        df[col] = le.transform(df[col])
        df[col] = df[col].astype(int)
        # $B7gB;$,$"$k>l9g(B, nan $B$r%;%C%H(B
        if is_deficit:
            df[col] = df[col].replace(fill_symbol, np.nan)
    print(f'transformed_cols: {transformed_cols}')
    return le_dict if inplace else df, le_dict


def _fill_unseen(serieses, fill_value):
    base_series, target_series = serieses
    unseen_vals = set(target_series.unique()) - set(base_series.unique())
    replace_dict = {val: fill_value for val in unseen_vals}
    return target_series.replace(replace_dict)


def fill_unseens(base_df, target_df, target_cols, nthread,
                 fill_value=np.nan, inplace=False):
    if not inplace:
        target_df = target_df.copy()

    with Pool(nthread) as p:
        series_pairs = [[base_df[col], target_df[col]] for col in target_cols]
        iter_func = partial(_fill_unseen, fill_value=fill_value)
        filled = p.map(iter_func, series_pairs)
        p.close()
        p.join()
    filled_df = pd.concat(filled, axis=1)

    for col in target_cols:
        target_df[col] = filled_df[col]
    return None if inplace else target_df


def count_clip_encoding(df):
    '''
    all df columns must be label encoded, and index must be MachineIdentifier.

    refferred the kernel.
    https://www.kaggle.com/bogorodvo/lightgbm-baseline-model-using-sparse-matrix/log

    '''
    nes_dir = './inputs/nes_info/'
    trn_ids = pd.read_pickle(
        nes_dir + 'trn_MachineIdentifier.pkl.gz', compression='gzip')
    tst_ids = pd.read_pickle(
        nes_dir + 'tst_MachineIdentifier.pkl.gz', compression='gzip')
    target_cols = df.columns.tolist()

    # nan 用に 0 を開けておく
    df = df + 1
    train = df.loc[trn_ids].reset_index()
    test = df.loc[tst_ids].reset_index()

    print(f'now count clip encoding the cols {target_cols} ...')
    for usecol in tqdm(target_cols):
        agg_tr = (train
                  .groupby([usecol])
                  .aggregate({'MachineIdentifier': 'count'})
                  .reset_index()
                  .rename({'MachineIdentifier': 'Train'}, axis=1))
        agg_te = (test
                  .groupby([usecol])
                  .aggregate({'MachineIdentifier': 'count'})
                  .reset_index()
                  .rename({'MachineIdentifier': 'Test'}, axis=1))

        agg = pd.merge(
            agg_tr,
            agg_te,
            on=usecol,
            how='outer').replace(
            np.nan,
            0)
        # Select values with more than 1000 observations
        agg = agg[(agg['Train'] > 1000)].reset_index(drop=True)
        agg['Total'] = agg['Train'] + agg['Test']
        # Drop unbalanced values
        agg = agg[(agg['Train'] / agg['Total'] > 0.2) &
                  (agg['Train'] / agg['Total'] < 0.8)]
        agg[usecol + 'Copy'] = agg[usecol]

        train[usecol] = (pd.merge(train[[usecol]],
                                  agg[[usecol, usecol + 'Copy']],
                                  on=usecol, how='left')[usecol + 'Copy']
                         .replace(np.nan, 0).astype('int').astype(train[usecol].dtype))

        test[usecol] = (pd.merge(test[[usecol]],
                                 agg[[usecol, usecol + 'Copy']],
                                 on=usecol, how='left')[usecol + 'Copy']
                        .replace(np.nan, 0).astype('int').astype(test[usecol].dtype))

        del agg_tr, agg_te, agg, usecol
        gc.collect()

    res_df = pd.DataFrame(df.index)
    trn_tst_df = pd.concat([train, test], axis=0)
    res_df = res_df.merge(trn_tst_df,
                          on='MachineIdentifier', how='left')\
        .set_index('MachineIdentifier')
    return res_df


def _get_freq_dict(series):
    t = series.value_counts().reset_index()
    t = t.reset_index()
    variable = t.columns[-1]
    t.loc[t[variable] == 1, 'level_0'] = np.nan
    t.set_index('index', inplace=True)
    max_label = t['level_0'].max() + 1
    t.fillna(max_label, inplace=True)
    return t.to_dict()['level_0']


def frequency_encoding(df):
    print('start frequency encoding ...')
    for col in tqdm(df.columns):
        freq_enc_dict = _get_freq_dict(df[col])
        df[col] = df[col].map(lambda x: freq_enc_dict.get(x, np.nan))
    return df
